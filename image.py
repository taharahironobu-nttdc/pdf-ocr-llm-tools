import base64
import json
import os
import sys
from pathlib import Path

import requests

# åˆ©ç”¨å¯èƒ½ãªVisionãƒ¢ãƒ‡ãƒ«
VISION_MODELS = {
    # ç„¡æ–™ãƒ¢ãƒ‡ãƒ« (æ¨å¥¨)
    "llama-vision-free": "meta-llama/llama-3.2-11b-vision-instruct:free",
    "qwen-32b-free": "qwen/qwen2.5-vl-32b-instruct:free",
    "qwen-72b-free": "qwen/qwen2.5-vl-72b-instruct:free",
    "kimi-vl-free": "moonshotai/kimi-vl-a3b-thinking:free",
    "gemma-4b-free": "google/gemma-3-4b-it:free",
    "gemma-12b-free": "google/gemma-3-12b-it:free",
    "gemma-27b-free": "google/gemma-3-27b-it:free",
    # æœ‰æ–™ãƒ¢ãƒ‡ãƒ«
    "llama-3.2-90b": "meta-llama/llama-3.2-90b-vision-instruct",
    "llama-3.2-11b": "meta-llama/llama-3.2-11b-vision-instruct",
    "gpt-4-vision": "openai/gpt-4-vision-preview",
    "gpt-4o": "openai/gpt-4o",
    "claude-3.5-sonnet": "anthropic/claude-3.5-sonnet",
    "gemini-1.5-pro": "google/gemini-pro-1.5",
    "pixtral-12b": "mistralai/pixtral-12b-2409",
}


def convert_pdf_to_images(pdf_path, dpi=200):
    """PDFã‚’ç”»åƒã«å¤‰æ›ã—ã¦ã€PDFãƒ•ã‚¡ã‚¤ãƒ«åã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜"""
    try:
        import fitz  # PyMuPDF

        # PDFãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã‚’ç”Ÿæˆ
        pdf_name = Path(pdf_path).stem
        output_dir = f"{pdf_name}_images"

        os.makedirs(output_dir, exist_ok=True)
        pdf = fitz.open(pdf_path)
        image_paths = []

        print(f"PDFã‚’ç”»åƒã«å¤‰æ›ä¸­: {len(pdf)} ãƒšãƒ¼ã‚¸")
        print(f"ä¿å­˜å…ˆ: {output_dir}/")

        for page_num, page in enumerate(pdf):
            # é«˜è§£åƒåº¦ã§å¤‰æ›
            zoom = dpi / 72  # 72 DPI base
            mat = fitz.Matrix(zoom, zoom)
            pix = page.get_pixmap(matrix=mat)
            image_path = f"{output_dir}/page_{page_num + 1:03d}.png"
            pix.save(image_path)
            image_paths.append(image_path)
            print(f"  ãƒšãƒ¼ã‚¸ {page_num + 1}/{len(pdf)} å¤‰æ›å®Œäº† -> {image_path}")

        pdf.close()
        return output_dir, image_paths
    except Exception as e:
        print(f"PDFå¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
        return None, None


def encode_image(image_path):
    """ç”»åƒã‚’Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰"""
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")


def ocr_with_openrouter(image_path, model, api_key):
    """OpenRouterã‚’ä½¿ã£ã¦OCRå®Ÿè¡Œ"""
    try:
        # ç”»åƒã‚’Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        base64_image = encode_image(image_path)

        # OpenRouter APIå‘¼ã³å‡ºã—
        response = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {api_key}",
                "HTTP-Referer": "https://github.com/pdf-converter",
                "X-Title": "PDF to Word Converter",
            },
            json={
                "model": model,
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": """ã“ã®ç”»åƒã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£ç¢ºã«æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

è¦ä»¶:
- ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã€è¡¨ã€ç®‡æ¡æ›¸ããªã©ã®æ§‹é€ ã‚’ä¿æŒ
- å‡ºåŠ›ã¯ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼
- ä½™è¨ˆãªèª¬æ˜ã¯ä¸è¦ã€ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã‚’å‡ºåŠ›
- æ—¥æœ¬èªã®å ´åˆã¯æ—¥æœ¬èªã§ã€è‹±èªã®å ´åˆã¯è‹±èªã§å‡ºåŠ›""",
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/png;base64,{base64_image}"
                                },
                            },
                        ],
                    }
                ],
                "max_tokens": 4000,
                "temperature": 0.1,
            },
            timeout=120,
        )

        if response.status_code == 200:
            result = response.json()
            return result["choices"][0]["message"]["content"]
        else:
            error_msg = response.json().get("error", {})
            print(f"OpenRouter APIã‚¨ãƒ©ãƒ¼: {response.status_code}")
            print(f"è©³ç´°: {error_msg}")
            return None

    except requests.exceptions.RequestException as e:
        print(f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except Exception as e:
        print(f"OCRã‚¨ãƒ©ãƒ¼: {e}")
        return None


def markdown_to_docx(markdown_text, output_path):
    """ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚’Wordãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«å¤‰æ›"""
    try:
        from docx import Document
        from docx.enum.text import WD_ALIGN_PARAGRAPH
        from docx.shared import Inches, Pt

        doc = Document()

        lines = markdown_text.split("\n")
        in_code_block = False
        in_table = False
        table_data = []

        for line in lines:
            # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®å‡¦ç†
            if line.strip().startswith("```"):
                in_code_block = not in_code_block
                continue

            if in_code_block:
                p = doc.add_paragraph(line)
                p.style = "Normal"
                run = p.runs[0]
                run.font.name = "Courier New"
                run.font.size = Pt(9)
                continue

            # ãƒ†ãƒ¼ãƒ–ãƒ«ã®å‡¦ç†
            if "|" in line and line.strip().startswith("|"):
                cells = [cell.strip() for cell in line.split("|")[1:-1]]
                if cells:
                    if not in_table:
                        in_table = True
                        table_data = [cells]
                    elif all(c.replace("-", "").strip() == "" for c in cells):
                        # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ˜ãƒƒãƒ€ãƒ¼åŒºåˆ‡ã‚Šè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
                        continue
                    else:
                        table_data.append(cells)
                continue
            elif in_table:
                # ãƒ†ãƒ¼ãƒ–ãƒ«çµ‚äº†ã€Word tableã¨ã—ã¦è¿½åŠ 
                if len(table_data) > 0:
                    table = doc.add_table(rows=len(table_data), cols=len(table_data[0]))
                    table.style = "Table Grid"
                    for i, row_data in enumerate(table_data):
                        for j, cell_data in enumerate(row_data):
                            table.rows[i].cells[j].text = cell_data
                table_data = []
                in_table = False

            # è¦‹å‡ºã—ã®å‡¦ç†
            if line.startswith("# "):
                doc.add_heading(line[2:], level=1)
            elif line.startswith("## "):
                doc.add_heading(line[3:], level=2)
            elif line.startswith("### "):
                doc.add_heading(line[4:], level=3)
            elif line.startswith("#### "):
                doc.add_heading(line[5:], level=4)
            # ç®‡æ¡æ›¸ãã®å‡¦ç†
            elif line.strip().startswith("- ") or line.strip().startswith("* "):
                doc.add_paragraph(line.strip()[2:], style="List Bullet")
            # ç•ªå·ä»˜ããƒªã‚¹ãƒˆã®å‡¦ç†
            elif line.strip() and line.strip()[0].isdigit() and ". " in line:
                text = (
                    line.strip().split(". ", 1)[1]
                    if ". " in line.strip()
                    else line.strip()
                )
                doc.add_paragraph(text, style="List Number")
            # å¤ªå­—ã®å‡¦ç†
            elif "**" in line:
                p = doc.add_paragraph()
                parts = line.split("**")
                for i, part in enumerate(parts):
                    run = p.add_run(part)
                    if i % 2 == 1:  # å¥‡æ•°ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯å¤ªå­—
                        run.bold = True
            # é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆ
            elif line.strip():
                doc.add_paragraph(line)
            else:
                # ç©ºè¡Œ
                doc.add_paragraph()

        # æœ€å¾Œã«ãƒ†ãƒ¼ãƒ–ãƒ«ãŒæ®‹ã£ã¦ã„ã‚‹å ´åˆ
        if in_table and table_data:
            table = doc.add_table(rows=len(table_data), cols=len(table_data[0]))
            table.style = "Table Grid"
            for i, row_data in enumerate(table_data):
                for j, cell_data in enumerate(row_data):
                    table.rows[i].cells[j].text = cell_data

        doc.save(output_path)
        return True
    except Exception as e:
        print(f"Wordå¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback

        traceback.print_exc()
        return False


def cleanup_temp_files(image_dir, image_paths):
    """ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤"""
    print(f"\nä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ä¸­: {image_dir}/")
    for img_path in image_paths:
        try:
            os.remove(img_path)
        except:
            pass

    try:
        os.rmdir(image_dir)
        print(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤: {image_dir}/")
    except:
        pass


def main():
    import argparse

    parser = argparse.ArgumentParser(
        description="PDFã‚’Wordã«å¤‰æ› (OpenRouterä½¿ç”¨)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=f"""
åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«:

ğŸ†“ ç„¡æ–™ãƒ¢ãƒ‡ãƒ« (ãŠã™ã™ã‚):
  qwen-72b-free        - Qwen2.5-VL 72B (æœ€ã‚‚é«˜æ€§èƒ½ã€ç„¡æ–™)
  qwen-32b-free        - Qwen2.5-VL 32B (ãƒãƒ©ãƒ³ã‚¹å‹ã€ç„¡æ–™)
  llama-vision-free    - Llama 3.2 11B Vision (æ±ç”¨ã€ç„¡æ–™)
  kimi-vl-free         - Kimi VL A3B (è»½é‡ã€ç„¡æ–™)
  gemma-27b-free       - Gemma 3 27B (Googleè£½ã€ç„¡æ–™)
  gemma-12b-free       - Gemma 3 12B (ä¸­ã‚µã‚¤ã‚ºã€ç„¡æ–™)
  gemma-4b-free        - Gemma 3 4B (è¶…è»½é‡ã€ç„¡æ–™)

ğŸ’° æœ‰æ–™ãƒ¢ãƒ‡ãƒ«:
  llama-3.2-90b        - Llama 3.2 90B Vision
  gpt-4o               - GPT-4o (OpenAI)
  claude-3.5-sonnet    - Claude 3.5 Sonnet (Anthropic)
  gemini-1.5-pro       - Gemini 1.5 Pro (Google)

ãŠã™ã™ã‚ã®ä½¿ã„åˆ†ã‘:
  - æ—¥æœ¬èªOCR: qwen-72b-free ã¾ãŸã¯ qwen-32b-free
  - è‹±èªOCR: llama-vision-free ã¾ãŸã¯ gemma-27b-free
  - é«˜é€Ÿå‡¦ç†: kimi-vl-free ã¾ãŸã¯ gemma-4b-free
""",
    )
    parser.add_argument("input_pdf", help="å…¥åŠ›PDFãƒ•ã‚¡ã‚¤ãƒ«")
    parser.add_argument("output_docx", nargs="?", help="å‡ºåŠ›Wordãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆçœç•¥å¯ï¼‰")
    parser.add_argument(
        "--model",
        default="qwen-72b-free",
        choices=list(VISION_MODELS.keys()),
        help="ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ« (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: qwen-72b-free, ç„¡æ–™)",
    )
    parser.add_argument("--api-key", help="OpenRouter APIã‚­ãƒ¼")
    parser.add_argument(
        "--keep-images",
        action="store_true",
        help="ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿æŒ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ä¿æŒã•ã‚Œã¾ã™)",
    )
    parser.add_argument(
        "--delete-images", action="store_true", help="å¤‰æ›å¾Œã«ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤"
    )
    parser.add_argument(
        "--dpi", type=int, default=200, help="ç”»åƒå¤‰æ›æ™‚ã®DPI (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 200)"
    )
    parser.add_argument(
        "--list-models", action="store_true", help="åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’è¡¨ç¤º"
    )

    args = parser.parse_args()

    if args.list_models:
        print("\nåˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«:")
        for short_name, full_name in VISION_MODELS.items():
            print(f"  {short_name:20s} -> {full_name}")
        return

    # APIã‚­ãƒ¼ã®å–å¾—
    api_key = args.api_key or os.environ.get("OPENROUTER_API_KEY")
    if not api_key:
        print("ã‚¨ãƒ©ãƒ¼: OPENROUTER_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print("\nä»¥ä¸‹ã®ã„ãšã‚Œã‹ã®æ–¹æ³•ã§è¨­å®šã—ã¦ãã ã•ã„:")
        print("1. export OPENROUTER_API_KEY='your-api-key'")
        print("2. python convert_openrouter.py input.pdf --api-key your-api-key")
        sys.exit(1)

    input_pdf = args.input_pdf
    if not os.path.exists(input_pdf):
        print(f"ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_pdf}")
        sys.exit(1)

    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æ±ºå®š
    if args.output_docx:
        output_docx = args.output_docx
    else:
        base_name = Path(input_pdf).stem
        output_docx = f"{base_name}.docx"

    model_full_name = VISION_MODELS[args.model]

    print(f"\n=== PDF to Word å¤‰æ› (OpenRouter) ===")
    print(f"å…¥åŠ›: {input_pdf}")
    print(f"å‡ºåŠ›: {output_docx}")
    print(f"ãƒ¢ãƒ‡ãƒ«: {args.model} ({model_full_name})")
    print(f"DPI: {args.dpi}\n")

    # Step 1: PDFã‚’ç”»åƒã«å¤‰æ›
    print("Step 1: PDFã‚’ç”»åƒã«å¤‰æ›ä¸­...")
    image_dir, image_paths = convert_pdf_to_images(input_pdf, dpi=args.dpi)
    if not image_paths:
        print("âœ— PDFå¤‰æ›å¤±æ•—")
        sys.exit(1)

    print(f"\nç”»åƒä¿å­˜å…ˆ: {image_dir}/")
    print(f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(image_paths)}\n")

    # Step 2: å„ãƒšãƒ¼ã‚¸ã‚’OCR
    print("\nStep 2: OCRå®Ÿè¡Œä¸­...")
    all_text = []

    for i, img_path in enumerate(image_paths, 1):
        print(f"  ãƒšãƒ¼ã‚¸ {i}/{len(image_paths)} å‡¦ç†ä¸­...")
        text = ocr_with_openrouter(img_path, model_full_name, api_key)
        if text:
            all_text.append(text)
            if i < len(image_paths):
                all_text.append("\n\n---\n\n")  # ãƒšãƒ¼ã‚¸åŒºåˆ‡ã‚Š
        else:
            print(f"  âš  ãƒšãƒ¼ã‚¸ {i} ã®OCRå¤±æ•—")

    if not all_text:
        print("\nâœ— å…¨ãƒšãƒ¼ã‚¸ã®OCRå¤±æ•—")
        if args.delete_images:
            cleanup_temp_files(image_dir, image_paths)
        sys.exit(1)

    # Step 3: Wordãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«å¤‰æ›
    print("\nStep 3: Wordæ–‡æ›¸ã«å¤‰æ›ä¸­...")
    combined_text = "".join(all_text)

    if markdown_to_docx(combined_text, output_docx):
        print(f"\nâœ“ å¤‰æ›æˆåŠŸ: {output_docx}")
    else:
        print("\nâš  Wordå¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ")
        # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        md_output = output_docx.replace(".docx", ".md")
        with open(md_output, "w", encoding="utf-8") as f:
            f.write(combined_text)
        print(f"  ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã¨ã—ã¦ä¿å­˜: {md_output}")

    # Step 4: ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    if args.delete_images:
        cleanup_temp_files(image_dir, image_paths)
    else:
        print(f"\nğŸ“ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {image_dir}/")
        print(f"   ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(image_paths)}")

    print("\nâœ… å®Œäº†!")


if __name__ == "__main__":
    main()
